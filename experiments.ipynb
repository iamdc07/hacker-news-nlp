{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# --------------------------------------------------------\n",
        "# Intro to AI: Project 2\n",
        "# Written by Dhaval Chavada(40078885) & Anand Kacha (40047673)\n",
        "# For COMP 6721 (Lab section - FK) - Fall 2019\n",
        "# --------------------------------------------------------\n",
        "\n",
        "import pandas as pd\n",
        "import gc\n",
        "import nltk\n",
        "import train\n",
        "import operator, math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, precision_recall_fscore_support, \\\n",
        "    confusion_matrix\n",
        "\n",
        "no_of_words = 0\n",
        "each_accuracy = 0\n",
        "\n",
        "labels = {\n",
        "    \"poll\": 0,\n",
        "    \"show_hn\": 1,\n",
        "    \"ask_hn\": 2,\n",
        "    \"story\": 3\n",
        "}\n",
        "\n",
        "plt.rcdefaults()\n",
        "\n",
        "\n",
        "def baseline(class_probability, df_testing, p_show_hn_dict, p_ask_hn_dict, p_poll_dict,\n",
        "             p_story_dict, exp):\n",
        "    gc.collect()\n",
        "\n",
        "    test_labels, predictions, title = classify(class_probability, df_testing, p_show_hn_dict, p_ask_hn_dict,\n",
        "                                               p_poll_dict,\n",
        "                                               p_story_dict, exp)\n",
        "\n",
        "    accuracy = accuracy_score(test_labels, predictions)\n",
        "    all_score = precision_recall_fscore_support(test_labels, predictions, labels=[0, 1, 2, 3])\n",
        "    precision = precision_score(test_labels, predictions, average=\"weighted\")\n",
        "    recall = recall_score(test_labels, predictions, average=\"weighted\")\n",
        "    f1 = f1_score(test_labels, predictions, average=\"weighted\")\n",
        "    c_f = confusion_matrix(test_labels, predictions)\n",
        "    print(\"\\nprecision: story - \", all_score[0][3], \" | ask_hn - \", all_score[0][2], \" | show_hn - \", all_score[0][1],\n",
        "          \" | poll - \", all_score[0][0])\n",
        "    print(\"recall: story - \", all_score[1][3], \" | ask_hn - \", all_score[1][2], \" | show_hn - \", all_score[1][1],\n",
        "          \" | poll - \", all_score[1][0])\n",
        "    print(\"F1 Measure: story - \", all_score[2][3], \" | ask_hn - \", all_score[2][2], \" | show_hn - \", all_score[2][1],\n",
        "          \" | poll - \", all_score[2][0])\n",
        "    print(\"\\nAccuracy:\", accuracy)\n",
        "    print(\"Precision:\", precision)\n",
        "    print(\"Recall:\", recall)\n",
        "    print(\"F1 Measure:\", f1)\n",
        "    print(\"Confusion Matrix:\\n\", c_f)\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "def stop_word_filtering():\n",
        "    global stop_words\n",
        "\n",
        "    stop_words_df = pd.read_csv(\"./Stopwords.txt\")\n",
        "    stop_words = stop_words_df[\"a\"].tolist()\n",
        "\n",
        "    train.read_file(2)\n",
        "\n",
        "\n",
        "def word_length_filtering():\n",
        "    train.read_file(3)\n",
        "\n",
        "\n",
        "def infrequent_word_filtering():\n",
        "    vocab_size = []\n",
        "    accuracy_list = []\n",
        "\n",
        "    i = 5\n",
        "\n",
        "    print(\"Remove words which have:\")\n",
        "    print(\"Frequency = \", 1)\n",
        "    train.remove_freq = i\n",
        "    train.read_file(4)\n",
        "    vocab_size.append(no_of_words)\n",
        "    if each_accuracy <= 0:\n",
        "        accuracy_list.append(0)\n",
        "    else:\n",
        "        accuracy_list.append(each_accuracy)\n",
        "\n",
        "    while i <= 20:\n",
        "        print(\"Frequency <= \", i)\n",
        "        train.remove_freq = i\n",
        "        train.read_file(4)\n",
        "        vocab_size.append(no_of_words)\n",
        "        if each_accuracy <= 0:\n",
        "            accuracy_list.append(0)\n",
        "            print(\"There is insufficient data in dataset to perform this experiment!\\n\")\n",
        "        else:\n",
        "            accuracy_list.append(each_accuracy)\n",
        "\n",
        "        i += 5\n",
        "\n",
        "    print(\"Accuracy list:\", accuracy_list)\n",
        "\n",
        "    objects = ('=1', '<=5', '<=10', '<=15', '<=20')\n",
        "    y_pos = np.arange(len(objects))\n",
        "\n",
        "    plt.bar(y_pos, accuracy_list, align='center', alpha=0.5, color=['black', 'red', 'green', 'blue', 'cyan'])\n",
        "    plt.xticks(y_pos, objects)\n",
        "    plt.xlabel('Frequency')\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.title('Performance of the classifiers against the number of words ')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "    i = 5\n",
        "    vocab_size.clear()\n",
        "    accuracy_list.clear()\n",
        "\n",
        "    while i <= 25:\n",
        "        print(i, \"% Frequent words\")\n",
        "        train.remove_percent = i / 100\n",
        "        train.read_file(4.5)\n",
        "        vocab_size.append(no_of_words)\n",
        "        if each_accuracy <= 0:\n",
        "            accuracy_list.append(0)\n",
        "            print(\"There is insufficient data in dataset to perform this experiment!\\n\")\n",
        "        else:\n",
        "            accuracy_list.append(each_accuracy)\n",
        "\n",
        "        i += 5\n",
        "\n",
        "    objects = ('5%', '10%', '15%', '20%', '25%')\n",
        "    y_pos = np.arange(len(objects))\n",
        "\n",
        "    plt.bar(y_pos, accuracy_list, align='center', alpha=0.5, color=['black', 'red', 'green', 'blue', 'cyan'])\n",
        "    plt.xticks(y_pos, objects)\n",
        "    plt.xlabel('Frequent words')\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.title('Performance of the classifiers against the number of words ')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def smoothing():\n",
        "    accuracy_list = []\n",
        "    smoothing_list = []\n",
        "\n",
        "    i = 0\n",
        "\n",
        "    while i <= 1:\n",
        "        print(\"Smoothing: \", format(i, '.1g'))\n",
        "        train.smoothing_value = i\n",
        "        train.read_file(5)\n",
        "        accuracy_list.append(each_accuracy)\n",
        "        smoothing_list.append(i)\n",
        "        i = i + 0.1\n",
        "\n",
        "    objects = ('0', '0.1', '0.2', '0.3', '0.4', '0.5', '0.6', '0.7', '0.8', '0.9', '1')\n",
        "    y_pos = np.arange(len(objects))\n",
        "\n",
        "    plt.bar(y_pos, accuracy_list, align='center', alpha=0.5, color=['black', 'red', 'green', 'blue', 'cyan'])\n",
        "    plt.xticks(y_pos, objects)\n",
        "    plt.xlabel('Smoothing')\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.title('Performance of the classifiers against the variation in smoothing ')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def classify(class_probability, df_testing, p_show_hn_dict, p_ask_hn_dict, p_poll_dict,\n",
        "             p_story_dict, exp):\n",
        "    title = \"NaN\"\n",
        "    title_list = []\n",
        "    test_labels = []\n",
        "    predictions = []\n",
        "\n",
        "    line_count = 1\n",
        "\n",
        "    for index, row in df_testing.iterrows():\n",
        "        title = row[\"Title\"]\n",
        "        post_type = row[\"Post Type\"]\n",
        "\n",
        "        tokenizer = nltk.RegexpTokenizer(r\"\\w+\", False, True)\n",
        "\n",
        "        raw = tokenizer.tokenize(title.lower())\n",
        "\n",
        "        if exp == 3:\n",
        "            new_words = [word for word in list(raw) if not (len(word) >= 9 or len(word) <= 2)]\n",
        "            raw = new_words\n",
        "            title = ' '.join([str(elem) for elem in new_words])\n",
        "\n",
        "        word_list = train.tokenize_word(raw, title, df_testing, index, set(), True)\n",
        "\n",
        "        # 0: show_hn\n",
        "        # 1: ask_hn\n",
        "        # 2: poll\n",
        "        # 3: story\n",
        "\n",
        "        if class_probability[3] == 0:\n",
        "            hypothesis_story = 0\n",
        "        else:\n",
        "            hypothesis_story = math.log10(class_probability[3])\n",
        "\n",
        "        if class_probability[1] == 0:\n",
        "            hypothesis_ask_hn = 0\n",
        "        else:\n",
        "            hypothesis_ask_hn = math.log10(class_probability[1])\n",
        "\n",
        "        if class_probability[0] == 0:\n",
        "            hypothesis_show_hn = 0\n",
        "        else:\n",
        "            hypothesis_show_hn = math.log10(class_probability[0])\n",
        "\n",
        "        if class_probability[2] == 0:\n",
        "            hypothesis_poll = 0\n",
        "        else:\n",
        "            hypothesis_poll = math.log10(class_probability[2])\n",
        "\n",
        "        for each_word in word_list:\n",
        "\n",
        "            if each_word in p_story_dict:\n",
        "                p_conditional_story = p_story_dict[each_word]\n",
        "                if p_conditional_story != 0:\n",
        "                    hypothesis_story += math.log10(p_conditional_story)\n",
        "                    hypothesis_story = int(hypothesis_story * 10 ** 10) / 10.0 ** 10\n",
        "\n",
        "            if each_word in p_ask_hn_dict:\n",
        "                p_conditional_ask_hn = p_ask_hn_dict[each_word]\n",
        "                if p_conditional_ask_hn != 0:\n",
        "                    hypothesis_ask_hn += math.log10(p_conditional_ask_hn)\n",
        "                    hypothesis_ask_hn = int(hypothesis_ask_hn * 10 ** 10) / 10.0 ** 10\n",
        "\n",
        "            if each_word in p_show_hn_dict:\n",
        "                p_conditional_show_hn = p_show_hn_dict[each_word]\n",
        "                if p_conditional_show_hn != 0:\n",
        "                    hypothesis_show_hn += math.log10(p_conditional_show_hn)\n",
        "                    hypothesis_show_hn = int(hypothesis_show_hn * 10 ** 10) / 10.0 ** 10\n",
        "\n",
        "            if each_word in p_poll_dict:\n",
        "                p_conditional_poll = p_poll_dict[each_word]\n",
        "                if p_conditional_poll != 0:\n",
        "                    hypothesis_poll += math.log10(p_conditional_poll)\n",
        "                    hypothesis_poll = int(hypothesis_poll * 10 ** 10) / 10.0 ** 10\n",
        "\n",
        "        temp_dict = {\n",
        "            \"poll\": hypothesis_poll,\n",
        "            \"show_hn\": hypothesis_show_hn,\n",
        "            \"ask_hn\": hypothesis_ask_hn,\n",
        "            \"story\": hypothesis_story\n",
        "        }\n",
        "\n",
        "        answer = {x: y for x, y in temp_dict.items() if y != 0}\n",
        "\n",
        "        prediction = max(answer.items(), key=operator.itemgetter(1))[0]\n",
        "        title_list.append(title)\n",
        "        test_labels.append(labels.get(post_type))\n",
        "        predictions.append(labels.get(max(answer.items(), key=operator.itemgetter(1))[0]))\n",
        "\n",
        "        if exp == 1:\n",
        "            file = open(\"baseline-result.txt\", \"a\")\n",
        "            file.write(str(line_count) + \" \" + title + \" \" + prediction + \" \" + str(\n",
        "                hypothesis_story) + \" \" + str(\n",
        "                hypothesis_ask_hn) + \" \" + str(hypothesis_show_hn) + \" \" + str(\n",
        "                hypothesis_poll) + \" \" + str(\n",
        "                post_type) + \" \" + (\"right\" if post_type == prediction else \"wrong\") + '\\n')\n",
        "            file.close()\n",
        "        elif exp == 2:\n",
        "            file = open(\"stopword-result.txt\", \"a\")\n",
        "            file.write(str(line_count) + \" \" + title + \" \" + prediction + \" \" + str(\n",
        "                hypothesis_story) + \" \" + str(\n",
        "                hypothesis_ask_hn) + \" \" + str(hypothesis_show_hn) + \" \" + str(\n",
        "                hypothesis_poll) + \" \" + str(\n",
        "                post_type) + \" \" + (\"right\" if post_type == prediction else \"wrong\") + '\\n')\n",
        "            file.close()\n",
        "        elif exp == 3:\n",
        "            file = open(\"wordlength-result.txt\", \"a\")\n",
        "            file.write(str(line_count) + \" \" + title + \" \" + prediction + \" \" + str(\n",
        "                hypothesis_story) + \" \" + str(\n",
        "                hypothesis_ask_hn) + \" \" + str(hypothesis_show_hn) + \" \" + str(\n",
        "                hypothesis_poll) + \" \" + str(\n",
        "                post_type) + \" \" + (\"right\" if post_type == prediction else \"wrong\") + '\\n')\n",
        "            file.close()\n",
        "        line_count += 1\n",
        "\n",
        "    return test_labels, predictions, title\n",
        "\n",
        "\n",
        "def select_experiment():\n",
        "    user_input = 0\n",
        "\n",
        "    while user_input != -1:\n",
        "        print(\"Choose your experiment\")\n",
        "        print(\"2. Stopwords\")\n",
        "        print(\"3. Word length Filtering\")\n",
        "        print(\"4. Infrequent Word Filtering\")\n",
        "        print(\"5. Smoothing\\n\")\n",
        "        print(\"Type '-1' to exit\")\n",
        "        user_input = int(input(\"Enter your choice:\"))\n",
        "\n",
        "        if user_input == 2:\n",
        "            stop_word_filtering()\n",
        "        elif user_input == 3:\n",
        "            word_length_filtering()\n",
        "        elif user_input == 4:\n",
        "            infrequent_word_filtering()\n",
        "        elif user_input == 5:\n",
        "            smoothing()\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}